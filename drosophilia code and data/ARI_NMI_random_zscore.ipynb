{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f25a132-fd12-4f3f-8d0b-760783234b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309976f-2261-47fa-8137-db956ca657c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ef8127-ca26-4b42-ab21-794ed6836f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories to store link and weight randomised networks corresponding \n",
    "# to our proposed strahler method reconstructed networks\n",
    "\n",
    "path = \"./random network/\"\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "for i in range(8):\n",
    "    path = \"./random network/janelia_Comm%d\"%i\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    for type in [\"link random\", \"weight random\"]:\n",
    "        path = \"./random network/janelia_Comm%d/\"%i+type\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        # pr refers to proximity range 1um and 5um.\n",
    "        for pr in [1,5]:\n",
    "            path = \"./random network/janelia_Comm%d/%s/network_%.1fum\"%(i,type,pr)\n",
    "            if not os.path.isdir(path):\n",
    "                os.mkdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9027b2a6-0d9a-4604-aa26-7c83701b96f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70312016-e002-4bc3-8982-e5aaa347d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes the network as input and randomises the link connection of the nodes\n",
    "# finally outputs dataframe consisting randomised edges hence link randomised network\n",
    "# here both the link connection changes as well as weight changes.\n",
    "\n",
    "def link_randomization(G, df):\n",
    "    n_edges = G.number_of_edges()\n",
    "\n",
    "    # setting the number of swaps based on documentation provided for function nx.directed_edge_swap()\n",
    "    G_rand = nx.directed_edge_swap(G, nswap = int(n_edges/3),\\\n",
    "                                   max_tries=int(n_edges/3)*1000)\n",
    "\n",
    "    df_rand = pd.DataFrame(list(G_rand.edges()), columns=[\"bodyId_pre\",\"bodyId_post\"])\n",
    "    weight_list = np.zeros(len(df_rand), dtype=int)\n",
    "    \n",
    "    for source in np.unique(df_rand.bodyId_pre.to_list()):\n",
    "        \n",
    "        source_ind =  np.argwhere(np.array(df_rand.bodyId_pre.to_list())==source).flatten() \n",
    "        \n",
    "        if source in df.bodyId_pre.to_list():\n",
    "            weight_samples = df[df.bodyId_pre==source].weight.to_list()\n",
    "            \n",
    "            np.random.shuffle(weight_samples)\n",
    "            weight_list[source_ind] = weight_samples\n",
    "        \n",
    "        else: # sample from weight distribution if source not in list\n",
    "            weights = df.weight.to_list()\n",
    "            n = len(weights)\n",
    "            \n",
    "            cdf = nx.utils.cumulative_distribution(weights)  # cdf of degree\n",
    "            discrete_sequence = nx.utils.discrete_sequence\n",
    "        \n",
    "            sampled_indices = discrete_sequence(n, cdistribution=cdf)\n",
    "            \n",
    "            weight_samples = np.array(weights)[sampled_indices]\n",
    "\n",
    "            weight_list[source_ind] = weight_samples\n",
    "    # insert new column to dataframe\n",
    "    df_rand[\"weight\"] = weight_list\n",
    "    return df_rand\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60e3ce4-c66e-488c-bde9-7aa64f851143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes the dataframe of network edges as input and randomly assigns the weight to the links.\n",
    "# The links between the edges are kept fixed but only the weights are rearranged.\n",
    "\n",
    "# finally outputs dataframe consisting weight randomised edges hence weight randomised network\n",
    "\n",
    "def weight_randomization(df):\n",
    "    # columns: bodiId_pre, body_ID_post, weight\n",
    "    weight_list = df.weight.to_list()\n",
    "    n = len(weight_list)\n",
    "    \n",
    "    cdf = nx.utils.cumulative_distribution(weight_list)  # cdf of weight\n",
    "    discrete_sequence = nx.utils.discrete_sequence\n",
    "\n",
    "    sampled_indices = discrete_sequence(n, cdistribution=cdf)\n",
    "    \n",
    "    new_weight_list = np.array(weight_list)[sampled_indices]\n",
    "\n",
    "    # Replace the 'weight' column with the new values\n",
    "    df.loc[:, 'weight'] = new_weight_list\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae7fbd8c-9f0f-41e4-abec-2881cd96cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comm 0\n",
      "pr 1\n",
      "pr 5\n",
      "Comm 1\n",
      "pr 1\n",
      "pr 5\n",
      "Comm 2\n",
      "pr 1\n",
      "pr 5\n",
      "Comm 3\n",
      "pr 1\n",
      "pr 5\n",
      "Comm 4\n",
      "pr 1\n",
      "pr 5\n",
      "Comm 5\n",
      "pr 1\n",
      "pr 5\n",
      "Comm 6\n",
      "pr 1\n",
      "pr 5\n",
      "Comm 7\n",
      "pr 1\n",
      "pr 5\n",
      "CPU times: user 19h 7min 20s, sys: 33min 19s, total: 19h 40min 40s\n",
      "Wall time: 19h 43min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data collection of random networks\n",
    "\n",
    "# store 100 realisations of link and weight randomised networks considering networks with proximity range\n",
    "# 1um and 5um. \n",
    "\n",
    "realizations=100\n",
    "\n",
    "for j in range(8):\n",
    "    print(\"Comm %d\"%j)\n",
    "            \n",
    "    for pr in [1, 5]:\n",
    "        print(\"pr\", pr)\n",
    "        \n",
    "        #print(\"prox range: %.1f um\"%pr)\n",
    "        nodes = pd.read_csv(\"./EM_communities/averageSubComm%d_drosophilia.csv\"%j).Node.to_list()\n",
    "        path = \"./janelia_Comm%d/\"%j\n",
    "        \n",
    "        df_network = pd.read_csv(path+\"network_%.1fum.txt\"%pr, sep=\"\\t\", header=None)\n",
    "        df_network = df_network.rename(columns={0: \"bodyId_pre\", 1: \"bodyId_post\", 2:\"weight\"})\n",
    "        \n",
    "        nodeA_list = df_network.bodyId_pre.tolist()\n",
    "        nodeB_list = df_network.bodyId_post.tolist()\n",
    "        weight_list = df_network.weight.tolist()\n",
    "        \n",
    "        # creating an edge list from adjacency matrix\n",
    "        edge_list=[]\n",
    "        for l,m,w in zip(nodeA_list, nodeB_list, weight_list):\n",
    "            edge_list.append( (l,m,{\"weight\":w}))\n",
    "            \n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Add all the nodes to the graph\n",
    "        G.add_nodes_from(nodes)\n",
    "        # Add all the edges to the graph\n",
    "        G.add_edges_from(edge_list)\n",
    "        \n",
    "        for type in [\"link random\", \"weight random\"]:\n",
    "            if type==\"link random\":\n",
    "                rand_path = \"./random network/janelia_Comm%d/%s/network_%.1fum/\"%(j,type,pr)\n",
    "                \n",
    "                for k in range(realizations):\n",
    "                    df_link_rand = link_randomization(G, df_network)\n",
    "                    df_link_rand.to_csv(rand_path+\"%d.csv\"%k, index=False)\n",
    "                \n",
    "            elif type==\"weight random\":    \n",
    "                rand_path = \"./random network/janelia_Comm%d/%s/network_%.1fum/\"%(j,type,pr)\n",
    "                for k in range(realizations):\n",
    "                    df_weight_rand = weight_randomization(df_network)\n",
    "                    df_link_rand.to_csv(rand_path+\"%d.csv\"%k, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0bdccb-9384-4467-b956-0f2ce99014c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c1d12bc-7e03-44c2-a177-db2b195a6b52",
   "metadata": {},
   "source": [
    "# Community detection applied on random networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b37cdfdf-9028-4a06-a4a9-505e2729c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories to store communities of random networks\n",
    "\n",
    "for i in range(8):\n",
    "    path = \"./random network/janelia_Comm%d\"%i\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "    for type in [\"link random\", \"weight random\"]:\n",
    "        path = \"./random network/janelia_Comm%d/\"%i+type\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "        \n",
    "        for pr in [1,5]:\n",
    "            path = \"./random network/janelia_Comm%d/%s/network_%.1fum_modules\"%(i,type,pr)\n",
    "            if not os.path.isdir(path):\n",
    "                os.mkdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc6e00c-c65a-4781-82f2-cf3e438ab8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leidenalg\n",
    "import igraph as ig\n",
    "from collections import Counter\n",
    "\n",
    "def Community_save(Graph, membership, filename):    \n",
    "    df = pd.DataFrame()\n",
    "    df['Node'] = Graph.vs['_nx_name']\n",
    "    df['Community'] = np.array(membership).astype(int)\n",
    "    \n",
    "    df.to_csv(filename+\".csv\", index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1a1592-798e-42b6-936c-4f34524b0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to networkx graph object\n",
    "def df_to_graph(nodes, df):\n",
    "    nodeA_list = df.bodyId_pre.tolist()\n",
    "    nodeB_list = df.bodyId_post.tolist()\n",
    "    weight_list = df.weight.tolist()\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add all the nodes to the graph\n",
    "    G.add_nodes_from(nodes)\n",
    "    \n",
    "    # creating an edge list from adjacency matrix\n",
    "    edge_list=[]\n",
    "    for l,m,w in zip(nodeA_list, nodeB_list, weight_list):\n",
    "        if (l in nodes) and (m in nodes):\n",
    "            #edge_list.append( (l,m,w))\n",
    "            G.add_edge(l, m, weight=w)\n",
    "            \n",
    "    # Add all the edges to the graph\n",
    "    #G.add_weighted_edges_from(edge_list)\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad931a5-ee80-4c4e-9515-44bbb8fb6f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9529a3da-3ab9-421f-a849-224078122829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess\n",
    "from functools import partial\n",
    "\n",
    "# function to save communities information\n",
    "# arguments meaning:\n",
    "# k: index for number of realisations 0 to 99\n",
    "# j: module number 0 to 7\n",
    "# type: link randomisation or weight randomisation\n",
    "# pr: specify proximity range 1um or 5um\n",
    "def save_comm_file(k, j, type, pr):\n",
    "    \n",
    "    path = \"./random network/janelia_Comm%d/%s/network_%.1fum/\"%(j,type,pr)\n",
    "    \n",
    "    df_network = pd.read_csv(path+\"%d.csv\"%k)\n",
    "    \n",
    "    nodeA_list = df_network.bodyId_pre.tolist()\n",
    "    nodeB_list = df_network.bodyId_post.tolist()\n",
    "    weight_list = df_network.weight.tolist()\n",
    "    \n",
    "    nodes = pd.read_csv(\"./EM_communities/averageSubComm%d_drosophilia.csv\"%j).Node.to_list()\n",
    "            \n",
    "    G = df_to_graph(nodes, df_network)\n",
    "    \n",
    "    G_ig = ig.Graph.from_networkx(G)\n",
    "    #try:\n",
    "    comm_membership = leidenalg.find_partition(G_ig,\\\n",
    "                                       leidenalg.ModularityVertexPartition,\\\n",
    "                                       weights=\"weight\")\n",
    "    #except Exception as e:\n",
    "    #    print(k, j, type, pr)\n",
    "\n",
    "    save_path = \"./random network/janelia_Comm%d/%s/network_%.1fum_modules/\"%(j,type,pr)\n",
    "        \n",
    "    Community_save(G_ig, comm_membership.membership, save_path+\"%d\"%k)\n",
    "\n",
    "    return None \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f125c6a8-a964-4d89-a0ac-6656207c7ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comm 0\n",
      "Comm 1\n",
      "Comm 2\n",
      "Comm 3\n",
      "Comm 4\n",
      "Comm 5\n",
      "Comm 6\n",
      "Comm 7\n",
      "CPU times: user 480 ms, sys: 601 ms, total: 1.08 s\n",
      "Wall time: 1h 41min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# parallelise applying community detection to each random network\n",
    "realizations=100\n",
    "\n",
    "for j in range(8):\n",
    "    print(\"Comm\", j)\n",
    "\n",
    "    for type in [\"link random\", \"weight random\"]:\n",
    "\n",
    "        for pr in [1,5]:\n",
    "\n",
    "            parallelised_func = partial( save_comm_file, j=j, type=type, pr=pr)\n",
    "        \n",
    "            pool = multiprocess.Pool( 7 )\n",
    "            _ = pool.map(parallelised_func, range(realizations))\n",
    "            pool.close()\n",
    "            pool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c0bd9-869d-4a26-bf61-0d3e68480f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5c7ca95-e847-4b05-a4d3-6600e245583e",
   "metadata": {},
   "source": [
    "# Compute ARI and NMI between communities 0-7 of EM drosophilia and reconstructed communities 0-7 from our proposed method \n",
    "\n",
    "### For example, it considers partition(set of subcommunities) of community 0 of EM drosophilia and partition of reconstructed community 0 using our method(strahler-threshold-proximity)\n",
    "\n",
    "\n",
    "ARI: Adjusted Rank Index\n",
    "\n",
    "\n",
    "NMI: Normalised Mutual Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fe6151-d04c-48a9-aca6-2d6f1f62a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition refers to set of community sets\n",
    "def ari_manual(partition1, partition2):\n",
    "    # partition2: dict with key:value \n",
    "    # key: leiden algorithm detected comme, value: node numbers\n",
    "    \n",
    "    # Check:\n",
    "    if sum([len(value) for value in partition2.values() ])!=sum([len(value) for value in partition1.values() ]):\n",
    "        print(\"total nodes of both partitions do not match!\")\n",
    "        return \n",
    "    \n",
    "    n = sum([len(value) for value in partition2.values() ])\n",
    "    nc2 = lambda x: x*(x-1)/2.0\n",
    "    \n",
    "    t1=0\n",
    "    for value1 in partition1.values():\n",
    "        for value2 in partition2.values():\n",
    "            nij = len(set(value1).intersection(set(value2)))\n",
    "            t1+=nc2(nij)\n",
    "    \n",
    "    t2 = 0        \n",
    "    for value1 in partition1.values():\n",
    "        ni_plus = len(value1)\n",
    "        t2+=nc2(ni_plus)    \n",
    "    \n",
    "    t3 = 0        \n",
    "    for value2 in partition2.values():\n",
    "        nj_plus = len(value2)\n",
    "        t3+=nc2(nj_plus)    \n",
    "    \n",
    "    ari  = ( t1 - (t2*t3/nc2(n)) ) /( 0.5*(t2+t3)- t2*t3/nc2(n))        \n",
    "    return ari\n",
    "    \n",
    "\n",
    "# this function inputs node-mapping-to-community file to dictionary\n",
    "# with keys as community numbers and values as list of nodes within the community\n",
    "def community_nodeNumbers_dict(comm_detection_file, main_comm=None): \n",
    "        df_comm = pd.read_csv(comm_detection_file)\n",
    "        comm_node_dict = {}\n",
    "        # UC only 7+1 communities\n",
    "        if main_comm==None:\n",
    "            main_comm = len(df_comm.Community.unique())\n",
    "            \n",
    "        for i in np.sort(df_comm.Community.unique())[:main_comm].astype(int):\n",
    "\n",
    "            comm_node_dict[\"C\"+str(i+1)] = df_comm[df_comm.Community == i].Node.tolist()\n",
    "        \n",
    "        return comm_node_dict\n",
    "\n",
    "\n",
    "\n",
    "def nmi_manual(partition1, partition2):\n",
    "    # partition2: dict with key:value \n",
    "    # key: leiden algorithm detected comme, value: node numbers\n",
    "    \n",
    "    # Check:\n",
    "    if sum([len(value) for value in partition2.values() ])!=sum([len(value) for value in partition1.values() ]):\n",
    "        print(\"total nodes of both partitions do not match!\")\n",
    "        return \n",
    "    \n",
    "    n = sum([len(value) for value in partition2.values() ])\n",
    "    #print(n)\n",
    "    I_matrix = np.zeros((len(partition1), len(partition2)))\n",
    "    pij_matrix = np.zeros((len(partition1), len(partition2)))\n",
    "    \n",
    "    i=0\n",
    "    for value1 in partition1.values():\n",
    "        ni_plus = len(value1)\n",
    "        j=0\n",
    "        for value2 in partition2.values():\n",
    "            nj_plus = len(value2)\n",
    "            nij = len(set(value1).intersection(set(value2)))\n",
    "            \n",
    "            pij_matrix[i,j] = nij/n\n",
    "            j+=1\n",
    "        i+=1\n",
    "        \n",
    "    for i in range(len(partition1.values())):\n",
    "        pi_plus = np.sum(pij_matrix[i,:])\n",
    "        \n",
    "        for j in range(len(partition2.values())):\n",
    "            pj_plus = np.sum(pij_matrix[:,j])\n",
    "            \n",
    "            if pij_matrix[i,j]!=0:\n",
    "                I_matrix[i,j] = -2*pij_matrix[i,j]*np.log2( pij_matrix[i,j]/(pi_plus*pj_plus)) \n",
    "            else:\n",
    "                I_matrix[i,j] = 0.0\n",
    "                \n",
    "    nmi = np.sum(I_matrix)/(np.sum(np.sum(pij_matrix,axis=0)*np.log2(np.sum(pij_matrix,axis=0) ))+\\\n",
    "                            np.sum(np.sum(pij_matrix,axis=1)*np.log2(np.sum(pij_matrix,axis=1) )))\n",
    "    \n",
    "    return nmi\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8129b11f-7bbb-490e-872c-3ce829286dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30ddc16a-1049-4468-8f82-6b2c276f081c",
   "metadata": {},
   "source": [
    "## Steps involved:\n",
    "1. Consider partition of module i of EM drosophilia and partition of module i reconstructed by our method(can be network reconstructed with prox. rang 1um and 5um).\n",
    "2. Compute similarity measures like ARI and NMI between these two partitions, for networks with prox ranges 1um, 5um and store the information as a dataframe df_ari_nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e87bae-6e9d-455a-b4dc-a29967a3cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sim_mean_std_rand(compute_similarity, j, type, pr):\n",
    "    path = \"./random network/janelia_Comm%d/%s/network_%.1fum_modules/\"%(j,type,pr)\n",
    "    sim_measure = []\n",
    "    #print(j, type, pr)\n",
    "    for k in range(realizations):\n",
    "        \n",
    "        # EM partitions\n",
    "        P1 = community_nodeNumbers_dict(\"./EM_communities/averageSubComm%d_drosophilia.csv\"%j)\n",
    "\n",
    "        # strahler partitions\n",
    "        P2 = community_nodeNumbers_dict(path+\"%d.csv\"%k)\n",
    "\n",
    "        if compute_similarity=='ari':\n",
    "            sim_measure.append(ari_manual(P1, P2))\n",
    "            \n",
    "        elif compute_similarity=='nmi':\n",
    "            sim_measure.append(nmi_manual(P1, P2))\n",
    "\n",
    "    return np.mean(sim_measure), np.std(sim_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59fa55e4-17c8-47c3-a263-c871abaa69f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.6 s, sys: 590 ms, total: 31.2 s\n",
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# computes the ari and nmi between module i of EM drosophilia and module i of reconstructed network \n",
    "# with proximty range 1um and 5um\n",
    "realizations=100\n",
    "ari_1um = []\n",
    "ariMean_linkRand_1um = []\n",
    "ariStd_linkRand_1um = []\n",
    "ariMean_weightRand_1um = []\n",
    "ariStd_weightRand_1um = []\n",
    "\n",
    "nmi_1um = []\n",
    "nmiMean_linkRand_1um = []\n",
    "nmiStd_linkRand_1um = []\n",
    "nmiMean_weightRand_1um = []\n",
    "nmiStd_weightRand_1um = []\n",
    "\n",
    "ari_5um = []\n",
    "ariMean_linkRand_5um = []\n",
    "ariStd_linkRand_5um = []\n",
    "ariMean_weightRand_5um = []\n",
    "ariStd_weightRand_5um = []\n",
    "\n",
    "nmi_5um = []\n",
    "nmiMean_linkRand_5um = []\n",
    "nmiStd_linkRand_5um = []\n",
    "nmiMean_weightRand_5um = []\n",
    "nmiStd_weightRand_5um = []\n",
    "\n",
    "for pr in [1,5]:\n",
    "    \n",
    "    for l in range(8):\n",
    "    \n",
    "        path = \"./janelia_Comm%d/\"%l\n",
    "        \n",
    "        # EM partitions, found by applying leiden algorithm to each of the 8 modules\n",
    "        P1 = community_nodeNumbers_dict(\"./EM_communities/averageSubComm%d_drosophilia.csv\"%l)\n",
    "        \n",
    "        # strahler partitions, found by applying leiden algorithm to each of the 8 reconstructed subnetworks\n",
    "        P2 = community_nodeNumbers_dict(path+\"SubComm%d_reconstructed_%.1fum.csv\"%(l,pr))\n",
    "\n",
    "        if pr==1:\n",
    "            ari_1um.append(ari_manual(P1, P2))\n",
    "            nmi_1um.append(nmi_manual(P1, P2))\n",
    "            \n",
    "            mean, std = sim_mean_std_rand('ari', l, 'link random', pr)\n",
    "            ariMean_linkRand_1um.append(mean)\n",
    "            ariStd_linkRand_1um.append(std)\n",
    "            \n",
    "            mean, std = sim_mean_std_rand('ari', l, 'weight random', pr)\n",
    "            ariMean_weightRand_1um.append(mean)\n",
    "            ariStd_weightRand_1um.append(std)\n",
    "            \n",
    "            \n",
    "            mean, std = sim_mean_std_rand('nmi', l, 'link random', pr)\n",
    "            nmiMean_linkRand_1um.append(mean)\n",
    "            nmiStd_linkRand_1um.append(std)\n",
    "\n",
    "            mean, std = sim_mean_std_rand('nmi', l, 'weight random', pr)\n",
    "            nmiMean_weightRand_1um.append(mean)\n",
    "            nmiStd_weightRand_1um.append(std)        \n",
    "\n",
    "        if pr==5:\n",
    "            ari_5um.append(ari_manual(P1, P2))\n",
    "            nmi_5um.append(nmi_manual(P1, P2))\n",
    "\n",
    "            mean, std = sim_mean_std_rand('ari', l, 'link random', pr)\n",
    "            ariMean_linkRand_5um.append(mean)\n",
    "            ariStd_linkRand_5um.append(std)\n",
    "            \n",
    "            mean, std = sim_mean_std_rand('ari', l, 'weight random', pr)\n",
    "            ariMean_weightRand_5um.append(mean)\n",
    "            ariStd_weightRand_5um.append(std)\n",
    "            \n",
    "            \n",
    "            mean, std = sim_mean_std_rand('nmi', l, 'link random', pr)\n",
    "            nmiMean_linkRand_5um.append(mean)\n",
    "            nmiStd_linkRand_5um.append(std)\n",
    "\n",
    "            mean, std = sim_mean_std_rand('nmi', l, 'weight random', pr)\n",
    "            nmiMean_weightRand_5um.append(mean)\n",
    "            nmiStd_weightRand_5um.append(std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd9ef5-7d08-47d7-887b-1ce8012e7e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b35c1821-34c2-41b8-aca7-a375ffd45711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modules</th>\n",
       "      <th>ARI 1um PR</th>\n",
       "      <th>ARI 5um PR</th>\n",
       "      <th>NMI 1um PR</th>\n",
       "      <th>NMI 5um PR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Module 0</td>\n",
       "      <td>0.398597</td>\n",
       "      <td>0.335102</td>\n",
       "      <td>0.545878</td>\n",
       "      <td>0.478728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Module 1</td>\n",
       "      <td>0.492287</td>\n",
       "      <td>0.497637</td>\n",
       "      <td>0.480612</td>\n",
       "      <td>0.503364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Module 2</td>\n",
       "      <td>0.353474</td>\n",
       "      <td>0.339324</td>\n",
       "      <td>0.414008</td>\n",
       "      <td>0.383208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Module 3</td>\n",
       "      <td>0.320013</td>\n",
       "      <td>0.324788</td>\n",
       "      <td>0.408120</td>\n",
       "      <td>0.409431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Module 4</td>\n",
       "      <td>0.192703</td>\n",
       "      <td>0.199708</td>\n",
       "      <td>0.253015</td>\n",
       "      <td>0.257254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Module 5</td>\n",
       "      <td>0.040915</td>\n",
       "      <td>0.037897</td>\n",
       "      <td>0.103048</td>\n",
       "      <td>0.098076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Module 6</td>\n",
       "      <td>0.486276</td>\n",
       "      <td>0.527616</td>\n",
       "      <td>0.514384</td>\n",
       "      <td>0.521734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Module 7</td>\n",
       "      <td>0.604465</td>\n",
       "      <td>0.602411</td>\n",
       "      <td>0.548925</td>\n",
       "      <td>0.558782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    modules  ARI 1um PR  ARI 5um PR  NMI 1um PR  NMI 5um PR\n",
       "0  Module 0    0.398597    0.335102    0.545878    0.478728\n",
       "1  Module 1    0.492287    0.497637    0.480612    0.503364\n",
       "2  Module 2    0.353474    0.339324    0.414008    0.383208\n",
       "3  Module 3    0.320013    0.324788    0.408120    0.409431\n",
       "4  Module 4    0.192703    0.199708    0.253015    0.257254\n",
       "5  Module 5    0.040915    0.037897    0.103048    0.098076\n",
       "6  Module 6    0.486276    0.527616    0.514384    0.521734\n",
       "7  Module 7    0.604465    0.602411    0.548925    0.558782"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ari_nmi = pd.DataFrame({\"modules\":[\"Module %d\"%i for i in range(8)],\n",
    "             \"ARI 1um PR\":ari_1um, \"ARI 5um PR\":ari_5um, \n",
    "             \"NMI 1um PR\":nmi_1um, \"NMI 5um PR\":nmi_5um})\n",
    "df_ari_nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "675fafdc-ed1e-428a-94e0-1b386cfeb75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{llrrrr}\\n\\\\toprule\\n & modules & ARI 1um PR & ARI 5um PR & NMI 1um PR & NMI 5um PR \\\\\\\\\\n\\\\midrule\\n0 & Module 0 & 0.398597 & 0.335102 & 0.545878 & 0.478728 \\\\\\\\\\n1 & Module 1 & 0.492287 & 0.497637 & 0.480612 & 0.503364 \\\\\\\\\\n2 & Module 2 & 0.353474 & 0.339324 & 0.414008 & 0.383208 \\\\\\\\\\n3 & Module 3 & 0.320013 & 0.324788 & 0.408120 & 0.409431 \\\\\\\\\\n4 & Module 4 & 0.192703 & 0.199708 & 0.253015 & 0.257254 \\\\\\\\\\n5 & Module 5 & 0.040915 & 0.037897 & 0.103048 & 0.098076 \\\\\\\\\\n6 & Module 6 & 0.486276 & 0.527616 & 0.514384 & 0.521734 \\\\\\\\\\n7 & Module 7 & 0.604465 & 0.602411 & 0.548925 & 0.558782 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ari_nmi.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8384e-4470-4f25-acd5-972d8467623b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ea429b8-9bf3-48fa-bad2-c17ec29afc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std = pd.DataFrame({\"modules\":[\"Module %d\"%(i+1) for i in range(8)],\n",
    "             \"ARI 1um PR\":ari_1um, \n",
    "            \"ariMean_linkRand_1um\":ariMean_linkRand_1um,\n",
    "            \"ariStd_linkRand_1um\":ariStd_linkRand_1um,\n",
    "            \"ariMean_weightRand_1um\":ariMean_weightRand_1um,\n",
    "            \"ariStd_weightRand_1um\":ariStd_weightRand_1um,\n",
    "           \n",
    "            \"ARI 5um PR\":ari_5um, \n",
    "           \"ariMean_linkRand_5um\":ariMean_linkRand_5um,\n",
    "            \"ariStd_linkRand_5um\":ariStd_linkRand_5um,\n",
    "            \"ariMean_weightRand_5um\":ariMean_weightRand_5um,\n",
    "            \"ariStd_weightRand_5um\":ariStd_weightRand_5um,\n",
    "             \n",
    "                            \n",
    "            \"NMI 1um PR\":nmi_1um, \n",
    "           \"nmiMean_linkRand_1um\":nmiMean_linkRand_1um,\n",
    "            \"nmiStd_linkRand_1um\":nmiStd_linkRand_1um,\n",
    "            \"nmiMean_weightRand_1um\":nmiMean_weightRand_1um,\n",
    "            \"nmiStd_weightRand_1um\":nmiStd_weightRand_1um,\n",
    "                            \n",
    "            \"NMI 5um PR\":nmi_5um,\n",
    "            \"nmiMean_linkRand_5um\":nmiMean_linkRand_5um,\n",
    "            \"nmiStd_linkRand_5um\":nmiStd_linkRand_5um,\n",
    "            \"nmiMean_weightRand_5um\":nmiMean_weightRand_5um,\n",
    "            \"nmiStd_weightRand_5um\":nmiStd_weightRand_5um\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62cfb7c5-284a-4e0b-9238-92245bcc5659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modules</th>\n",
       "      <th>ARI 1um PR</th>\n",
       "      <th>ariMean_linkRand_1um</th>\n",
       "      <th>ariStd_linkRand_1um</th>\n",
       "      <th>ariMean_weightRand_1um</th>\n",
       "      <th>ariStd_weightRand_1um</th>\n",
       "      <th>ARI 5um PR</th>\n",
       "      <th>ariMean_linkRand_5um</th>\n",
       "      <th>ariStd_linkRand_5um</th>\n",
       "      <th>ariMean_weightRand_5um</th>\n",
       "      <th>...</th>\n",
       "      <th>NMI 1um PR</th>\n",
       "      <th>nmiMean_linkRand_1um</th>\n",
       "      <th>nmiStd_linkRand_1um</th>\n",
       "      <th>nmiMean_weightRand_1um</th>\n",
       "      <th>nmiStd_weightRand_1um</th>\n",
       "      <th>NMI 5um PR</th>\n",
       "      <th>nmiMean_linkRand_5um</th>\n",
       "      <th>nmiStd_linkRand_5um</th>\n",
       "      <th>nmiMean_weightRand_5um</th>\n",
       "      <th>nmiStd_weightRand_5um</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Module 1</td>\n",
       "      <td>0.398597</td>\n",
       "      <td>0.026325</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.335102</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545878</td>\n",
       "      <td>0.047249</td>\n",
       "      <td>0.025894</td>\n",
       "      <td>0.035319</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.478728</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.000931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Module 2</td>\n",
       "      <td>0.492287</td>\n",
       "      <td>0.031899</td>\n",
       "      <td>0.037837</td>\n",
       "      <td>0.040584</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.497637</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.018036</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480612</td>\n",
       "      <td>0.044644</td>\n",
       "      <td>0.034767</td>\n",
       "      <td>0.045521</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.503364</td>\n",
       "      <td>0.012870</td>\n",
       "      <td>0.019109</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Module 3</td>\n",
       "      <td>0.353474</td>\n",
       "      <td>0.042762</td>\n",
       "      <td>0.038554</td>\n",
       "      <td>0.027302</td>\n",
       "      <td>0.014775</td>\n",
       "      <td>0.339324</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.012423</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414008</td>\n",
       "      <td>0.037651</td>\n",
       "      <td>0.024369</td>\n",
       "      <td>0.030067</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.383208</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.007766</td>\n",
       "      <td>0.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Module 4</td>\n",
       "      <td>0.320013</td>\n",
       "      <td>0.054720</td>\n",
       "      <td>0.071856</td>\n",
       "      <td>0.025299</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.324788</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>0.030591</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408120</td>\n",
       "      <td>0.069852</td>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.047961</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.409431</td>\n",
       "      <td>0.012120</td>\n",
       "      <td>0.030831</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Module 5</td>\n",
       "      <td>0.192703</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.020256</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.199708</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253015</td>\n",
       "      <td>0.053703</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.047402</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.257254</td>\n",
       "      <td>0.014089</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Module 6</td>\n",
       "      <td>0.040915</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.009150</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.037897</td>\n",
       "      <td>0.011176</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103048</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.014550</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.098076</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Module 7</td>\n",
       "      <td>0.486276</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>0.028995</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.527616</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514384</td>\n",
       "      <td>0.043254</td>\n",
       "      <td>0.024993</td>\n",
       "      <td>0.030088</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.521734</td>\n",
       "      <td>0.015981</td>\n",
       "      <td>0.011033</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Module 8</td>\n",
       "      <td>0.604465</td>\n",
       "      <td>0.180963</td>\n",
       "      <td>0.041628</td>\n",
       "      <td>0.199500</td>\n",
       "      <td>0.016076</td>\n",
       "      <td>0.602411</td>\n",
       "      <td>0.073226</td>\n",
       "      <td>0.053546</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548925</td>\n",
       "      <td>0.137370</td>\n",
       "      <td>0.026863</td>\n",
       "      <td>0.140082</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.558782</td>\n",
       "      <td>0.071392</td>\n",
       "      <td>0.029576</td>\n",
       "      <td>0.071986</td>\n",
       "      <td>0.002637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    modules  ARI 1um PR  ariMean_linkRand_1um  ariStd_linkRand_1um  \\\n",
       "0  Module 1    0.398597              0.026325             0.025100   \n",
       "1  Module 2    0.492287              0.031899             0.037837   \n",
       "2  Module 3    0.353474              0.042762             0.038554   \n",
       "3  Module 4    0.320013              0.054720             0.071856   \n",
       "4  Module 5    0.192703              0.023575             0.004674   \n",
       "5  Module 6    0.040915              0.004752             0.009150   \n",
       "6  Module 7    0.486276              0.021560             0.028995   \n",
       "7  Module 8    0.604465              0.180963             0.041628   \n",
       "\n",
       "   ariMean_weightRand_1um  ariStd_weightRand_1um  ARI 5um PR  \\\n",
       "0                0.014135               0.002598    0.335102   \n",
       "1                0.040584               0.005878    0.497637   \n",
       "2                0.027302               0.014775    0.339324   \n",
       "3                0.025299               0.004239    0.324788   \n",
       "4                0.020256               0.003516    0.199708   \n",
       "5                0.002823               0.000781    0.037897   \n",
       "6                0.008966               0.002509    0.527616   \n",
       "7                0.199500               0.016076    0.602411   \n",
       "\n",
       "   ariMean_linkRand_5um  ariStd_linkRand_5um  ariMean_weightRand_5um  ...  \\\n",
       "0              0.001720             0.007590                0.000941  ...   \n",
       "1              0.003016             0.018036                0.000675  ...   \n",
       "2              0.001886             0.012423                0.000339  ...   \n",
       "3              0.005406             0.030591                0.000146  ...   \n",
       "4              0.001295             0.001425                0.000613  ...   \n",
       "5              0.011176             0.003448                0.012266  ...   \n",
       "6              0.001199             0.006795               -0.000391  ...   \n",
       "7              0.073226             0.053546                0.084500  ...   \n",
       "\n",
       "   NMI 1um PR  nmiMean_linkRand_1um  nmiStd_linkRand_1um  \\\n",
       "0    0.545878              0.047249             0.025894   \n",
       "1    0.480612              0.044644             0.034767   \n",
       "2    0.414008              0.037651             0.024369   \n",
       "3    0.408120              0.069852             0.052525   \n",
       "4    0.253015              0.053703             0.005666   \n",
       "5    0.103048              0.013457             0.014550   \n",
       "6    0.514384              0.043254             0.024993   \n",
       "7    0.548925              0.137370             0.026863   \n",
       "\n",
       "   nmiMean_weightRand_1um  nmiStd_weightRand_1um  NMI 5um PR  \\\n",
       "0                0.035319               0.003281    0.478728   \n",
       "1                0.045521               0.003910    0.503364   \n",
       "2                0.030067               0.007882    0.383208   \n",
       "3                0.047961               0.005204    0.409431   \n",
       "4                0.047402               0.003247    0.257254   \n",
       "5                0.010483               0.001210    0.098076   \n",
       "6                0.030088               0.002726    0.521734   \n",
       "7                0.140082               0.005337    0.558782   \n",
       "\n",
       "   nmiMean_linkRand_5um  nmiStd_linkRand_5um  nmiMean_weightRand_5um  \\\n",
       "0              0.011300             0.009317                0.008817   \n",
       "1              0.012870             0.019109                0.010474   \n",
       "2              0.008613             0.007223                0.007766   \n",
       "3              0.012120             0.030831                0.006399   \n",
       "4              0.014089             0.002631                0.012477   \n",
       "5              0.010686             0.002470                0.010470   \n",
       "6              0.015981             0.011033                0.014599   \n",
       "7              0.071392             0.029576                0.071986   \n",
       "\n",
       "   nmiStd_weightRand_5um  \n",
       "0               0.000931  \n",
       "1               0.001134  \n",
       "2               0.001050  \n",
       "3               0.000868  \n",
       "4               0.000743  \n",
       "5               0.001276  \n",
       "6               0.001613  \n",
       "7               0.002637  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "775a4559-b14c-49c5-8465-40a1f1177139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_std.to_csv(\"ariNmi_randMean_std.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cc496-dfa8-4522-94fc-7b9870251b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e7df5fc-fea2-4ebd-87f5-319617cf67a0",
   "metadata": {},
   "source": [
    "# Computing Z-score\n",
    "### The method for computing z-score is described in more details on the following links for reference:\n",
    "\n",
    "https://github.com/netneurolab/conn2res/blob/master/examples/example1_figs.py\n",
    "\n",
    "https://www.nature.com/articles/s41467-024-44900-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335e92c-2bad-4504-bdcd-9e1c05c682f4",
   "metadata": {},
   "source": [
    "## Steps for computing z-score of ARI and NMI:\n",
    "\n",
    "1. Consider partition of module i of EM drosophilia and partition of module i reconstructed by our method(can be network reconstructed with prox. rang 1um and 5um).\n",
    "2. Compute similarity measures like ARI and NMI between these two partitions, for networks with prox ranges 1um, 5um\n",
    "3. For these above computed ARIs and NMIs, z-scores are computed on these measures using mean and standard deviations of ARIs/NMIs of random networks.\n",
    "4. store the information as a dataframe df_ari_nmi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72124ce9-1d45-4270-a084-deb00a52d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e215df2c-495e-43fa-bdf7-390c1d594ffa",
   "metadata": {},
   "source": [
    "# Steps for computing z-score of ARI and NMI, corresponding random networks and visualising through strip plots\n",
    "\n",
    "\n",
    "1. Similar to computation of above, now ARI and NMI are computed using the (partitions-of)modules corresponding to randomised version of the reconstructed networks(prox range(pr) 1um and 5um) and (partitions-of)modules of EM drosphilia. \n",
    "2. For these above computed ARIs and NMIs, z-scores are computed on these measures using mean and standard deviations of ARIs/NMIs of random networks.\n",
    "3. All these data are visualised as stripplot indicating how close or far the scattered black point corresponding to ARI/NMI of empirical model(our model i.e. df_ari_nmi) and other scattered points is from remaning ARIs/NMIs of randomised versions of networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0893584-54da-4205-bd4e-7e55ffe9b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function outputs:\n",
    "# df: z-scores of ARI/NMI corresponding to random networks themselves\n",
    "# df_emp: z-scores of ARI/NMI correspnding to model reconstructed networks\n",
    "\n",
    "# list of aruguments as input to the function\n",
    "# module_num: specify the community or module number 0 to 7\n",
    "# compute_similarity: specify ARI or NMI, to specify the measure between two partitions \n",
    "# type: specify 'link random' or 'weight random' referring to random networks \n",
    "# realizations: 100  \n",
    "# df_ari_nmi: dataframe consisting of ARIs/NMIs computed between module partitions of EM drosophilia \n",
    "# and reconstructed network\n",
    "\n",
    "def get_emp_null_df(module_num, compute_similarity, type, realizations, df_ari_nmi):\n",
    "    \n",
    "    j = module_num\n",
    "            \n",
    "    sim_network_dict = {\"1um\":[], \"5um\":[]}\n",
    "\n",
    "    # RANDOM NETWORKS\n",
    "    # compute z-score of the ARI/NMI of the null models itself.\n",
    "    for pr in [1,5]:\n",
    "    \n",
    "        path = \"./random network/janelia_Comm%d/%s/network_%.1fum_modules/\"%(j,type,pr)\n",
    "        #print(j, type, pr)\n",
    "        for k in range(realizations):\n",
    "            # EM partitions\n",
    "            P1 = community_nodeNumbers_dict(\"./EM_communities/averageSubComm%d_drosophilia.csv\"%j)\n",
    "    \n",
    "            # strahler partitions\n",
    "            P2 = community_nodeNumbers_dict(path+\"%d.csv\"%k)\n",
    "    \n",
    "            if compute_similarity=='ari':\n",
    "                sim_network_dict[\"%dum\"%pr].append(ari_manual(P1, P2))\n",
    "            \n",
    "            elif compute_similarity=='nmi':\n",
    "                sim_network_dict[\"%dum\"%pr].append(nmi_manual(P1, P2))\n",
    "    \n",
    "    df = pd.DataFrame({\"network pr\":[\"1um\"]*realizations+[\"5um\"]*realizations,\n",
    "                    \"sim_measure\":sim_network_dict[\"1um\"]+sim_network_dict[\"5um\"]})\n",
    "    \n",
    "    # z-score null model values\n",
    "    z_list = []\n",
    "    for pr in [1,5]:\n",
    "        df_network = df[df[\"network pr\"]==\"%dum\"%pr]\n",
    "        z_list+= list((df_network['sim_measure']-df_network['sim_measure'].mean())/df_network['sim_measure'].std())\n",
    "    \n",
    "    df['z-score'] = z_list\n",
    "\n",
    "\n",
    "\n",
    "    ##############  EMPIRICAL DATAFRAME/MODEL RECONSTRUCTED NETWORKS   ####################\n",
    "    emp_z_score_list = []\n",
    "    pval_list = []\n",
    "    \n",
    "    for pr in [1,5]:\n",
    "        if compute_similarity==\"ari\":\n",
    "            res = df_ari_nmi.iloc[[j]][\"ARI %dum PR\"%pr].values[0]\n",
    "        \n",
    "        elif compute_similarity==\"nmi\":\n",
    "            res = df_ari_nmi.iloc[[j]][\"NMI %dum PR\"%pr].values[0]\n",
    "        \n",
    "        df_network = df[df[\"network pr\"]==\"%dum\"%pr]\n",
    "        val = df_network[\"sim_measure\"]\n",
    "        z_score_emp = (res-np.mean(val))/np.std(val)\n",
    "        \n",
    "        emp_z_score_list.append(z_score_emp)\n",
    "        \n",
    "        # determine p-value\n",
    "        count = len(np.where(df_network[\"z-score\"].to_numpy() > z_score_emp)[0])\n",
    "        n_nulls = len(df_network)\n",
    "        pval_list.append( count / n_nulls )\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_emp = pd.DataFrame( {\"network pr\":[\"1um\", \"5um\"],\n",
    "                          \"z-score\":emp_z_score_list,\n",
    "                         \"p-val\":pval_list} )\n",
    "\n",
    "    return df, df_emp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9fe7710d-2dfd-42f5-876b-db9c2c6b4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising the z scores of our model(strahler-threshold-proximity based reconstructed network) \n",
    "# and randomised networks using striplots.\n",
    "\n",
    "def striplot(module_num, compute_similarity, type, df, df_emp):\n",
    "    j=module_num\n",
    "    import seaborn as sns\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # plot empirical vs null scores (z-scored) at critical alpha\n",
    "    sns.set(style=\"ticks\", font_scale=1.0)\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = plt.subplot(111)\n",
    "    \n",
    "    sns.scatterplot(\n",
    "        data=df_emp,\n",
    "        x='network pr',\n",
    "        y='z-score',\n",
    "        s=30,\n",
    "        c='black',\n",
    "        ax=ax,\n",
    "        \n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=df,\n",
    "        x='network pr',\n",
    "        y='z-score',\n",
    "        # width=0.5,\n",
    "        s=2.5,\n",
    "        jitter=0.3,\n",
    "        ax=ax,\n",
    "        \n",
    "    )\n",
    "    #ax.set_ylim(-3, 12.5)\n",
    "    sns.despine(offset=10, trim=True,\n",
    "                top=True, bottom=False,\n",
    "                right=True, left=False)\n",
    "    \n",
    "    # print p-value\n",
    "    label=\"1um p-val = %f \\n5um p-val = %f\"%(df_emp[df_emp[\"network pr\"]==\"1um\"][\"p-val\"],\n",
    "                                            df_emp[df_emp[\"network pr\"]==\"5um\"][\"p-val\"])\n",
    "    l1 = ax.plot([],[], label=label)\n",
    "    \n",
    "    # Add a legend with custom handles and labels\n",
    "    ax.legend(bbox_to_anchor=(1.3, 0.9), loc='upper right', \n",
    "              prop={'size': 9}, handlelength=0)\n",
    "    \n",
    "    #plt.legend(loc='best')\n",
    "    if type==\"link random\":\n",
    "        plt.title(\"Module: %d\"%(j+1)+\", \"+compute_similarity+\", \"+\"Directed Configuration model\", size=12)\n",
    "    else: \n",
    "        plt.title(\"Module: %d\"%(j+1)+\", \"+compute_similarity+\", \"+\"weight randomization\", size=12)\n",
    "        \n",
    "    #plt.show()\n",
    "    image_path = \"./random network/images/module%d/\"%(j+1)\n",
    "    plt.savefig(image_path+\"mod%d_%s_%s.pdf\"%(j+1, compute_similarity, type),\\\n",
    "                facecolor=\"white\", bbox_inches=\"tight\", dpi=600 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb922d4f-8c89-4ced-af77-e6f37f9d8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./random network/images/\"\n",
    "if not os.path.isdir(image_path):\n",
    "    os.mkdir(image_path)\n",
    "    \n",
    "for j in range(8):\n",
    "    image_path = \"./random network/images/module%d\"%(j+1)\n",
    "    if not os.path.isdir(image_path):\n",
    "        os.mkdir(image_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45245855-6a45-4ed2-a91b-6cfe8417341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "realizations=100\n",
    "\n",
    "\n",
    "for module_num in range(8):\n",
    "    for compute_similarity in ['ari', 'nmi']:\n",
    "        for type in [\"link random\", \"weight random\"]:\n",
    "\n",
    "            df, df_emp = get_emp_null_df(module_num, compute_similarity, type, realizations, df_ari_nmi)\n",
    "            striplot(module_num, compute_similarity, type, df, df_emp)\n",
    "            plt.close()\n",
    "            #print(df_emp)\n",
    "            #print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed9c3e-0150-4578-84a2-c951eb26de5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c92049d5-e9fe-4dda-823e-a6befbb49e78",
   "metadata": {},
   "source": [
    "# Computing pearson correlation\n",
    "\n",
    "1. Modules or communities from EM drosophilia are first converted to adjacency matrix\n",
    "2. Similarly, the reconstructed networks(prox range 1um and 5um) of nodes-grouped according to modules of EM are converted to adjacency matrix.\n",
    "\n",
    "3. Finally pearson correlation is computed between these two adjacency matrices to determine the level of correlation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724ac8c9-5818-4b83-b39c-f8734228f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff5ec47c-0e98-4ba1-9926-f9fb9a830cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proximity range: 1 um\n",
      "Module \t pearson_corr \t p_val\n",
      "Module 0 \t 0.157 \t 0.000\n",
      "Module 1 \t 0.079 \t 0.000\n",
      "Module 2 \t 0.136 \t 0.000\n",
      "Module 3 \t 0.218 \t 0.000\n",
      "Module 4 \t 0.051 \t 0.000\n",
      "Module 5 \t 0.198 \t 0.000\n",
      "Module 6 \t 0.185 \t 0.000\n",
      "Module 7 \t 0.146 \t 0.000\n"
     ]
    }
   ],
   "source": [
    "pr=1\n",
    "\n",
    "print(\"Proximity range: %d um\"%pr)\n",
    "print(\"Module \\t pearson_corr \\t p_val\")\n",
    "\n",
    "for j in range(8):\n",
    "\n",
    "    nodes = pd.read_csv(\"./EM_communities/averageSubComm%d_drosophilia.csv\"%j).Node.to_list()\n",
    "    \n",
    "    # EM network for Module j\n",
    "    \n",
    "    df = pd.read_csv(\"traced-total-connections.csv\")\n",
    "    nodeA_list = df.bodyId_pre.tolist()\n",
    "    nodeB_list = df.bodyId_post.tolist()\n",
    "    weight_list = df.weight.tolist()\n",
    "    \n",
    "    # creating an edge list from adjacency matrix\n",
    "    edge_list=[]\n",
    "    for l,m,w in zip(nodeA_list, nodeB_list, weight_list):\n",
    "        if (l in nodes) and (m in nodes):\n",
    "            edge_list.append( (l,m,{\"weight\":w}))\n",
    "    \n",
    "    G_EM = nx.DiGraph()\n",
    "    \n",
    "    # Add all the nodes to the graph\n",
    "    G_EM.add_nodes_from(nodes)\n",
    "    # Add all the edges to the graph\n",
    "    G_EM.add_edges_from(edge_list)\n",
    "    \n",
    "    mod_EM_adjacency = nx.adjacency_matrix(G_EM, nodelist=nodes, weight='weight')\n",
    "    \n",
    "    \n",
    "    path = \"./janelia_Comm%d/\"%j\n",
    "    \n",
    "    df_network = pd.read_csv(path+\"network_%.1fum.txt\"%pr, sep=\"\\t\", header=None)\n",
    "    df_network = df_network.rename(columns={0: \"bodyId_pre\", 1: \"bodyId_post\", 2:\"weight\"})\n",
    "    \n",
    "    nodeA_list = df_network.bodyId_pre.tolist()\n",
    "    nodeB_list = df_network.bodyId_post.tolist()\n",
    "    weight_list = df_network.weight.tolist()\n",
    "    \n",
    "    # creating an edge list from adjacency matrix\n",
    "    edge_list=[]\n",
    "    for l,m,w in zip(nodeA_list, nodeB_list, weight_list):\n",
    "        if (l in nodes) and (m in nodes):\n",
    "            edge_list.append( (l,m,{\"weight\":w}))\n",
    "        \n",
    "    G_strah = nx.DiGraph()\n",
    "    \n",
    "    # Add all the nodes to the graph\n",
    "    G_strah.add_nodes_from(nodes)\n",
    "    # Add all the edges to the graph\n",
    "    G_strah.add_edges_from(edge_list)\n",
    "    mod_strah_adjacency = nx.adjacency_matrix(G_strah, nodelist=nodes, weight='weight')\n",
    "    \n",
    "    corr_info = pearsonr(mod_EM_adjacency.toarray().flatten(), mod_strah_adjacency.toarray().flatten())\n",
    "    print(\"Module %d \\t %.3f \\t %.3f\"%(j, corr_info.statistic, corr_info.pvalue))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f5a7093-069d-4bd1-bc63-c13e5efce40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proximity range: 5 um\n",
      "Module \t pearson_corr \t p_val\n",
      "Module 0 \t 0.148 \t 0.000\n",
      "Module 1 \t 0.074 \t 0.000\n",
      "Module 2 \t 0.128 \t 0.000\n",
      "Module 3 \t 0.201 \t 0.000\n",
      "Module 4 \t 0.050 \t 0.000\n",
      "Module 5 \t 0.214 \t 0.000\n",
      "Module 6 \t 0.161 \t 0.000\n",
      "Module 7 \t 0.144 \t 0.000\n",
      "CPU times: user 8min 56s, sys: 918 ms, total: 8min 57s\n",
      "Wall time: 8min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pr=5\n",
    "\n",
    "print(\"Proximity range: %d um\"%pr)\n",
    "print(\"Module \\t pearson_corr \\t p_val\")\n",
    "\n",
    "for j in range(8):\n",
    "\n",
    "    nodes = pd.read_csv(\"./EM_communities/averageSubComm%d_drosophilia.csv\"%j).Node.to_list()\n",
    "    \n",
    "    # EM network for Module j\n",
    "    \n",
    "    df = pd.read_csv(\"traced-total-connections.csv\")\n",
    "    nodeA_list = df.bodyId_pre.tolist()\n",
    "    nodeB_list = df.bodyId_post.tolist()\n",
    "    weight_list = df.weight.tolist()\n",
    "    \n",
    "    # creating an edge list from adjacency matrix\n",
    "    edge_list=[]\n",
    "    for l,m,w in zip(nodeA_list, nodeB_list, weight_list):\n",
    "        if (l in nodes) and (m in nodes):\n",
    "            edge_list.append( (l,m,{\"weight\":w}))\n",
    "    \n",
    "    G_EM = nx.DiGraph()\n",
    "    \n",
    "    # Add all the nodes to the graph\n",
    "    G_EM.add_nodes_from(nodes)\n",
    "    # Add all the edges to the graph\n",
    "    G_EM.add_edges_from(edge_list)\n",
    "    \n",
    "    mod_EM_adjacency = nx.adjacency_matrix(G_EM, nodelist=nodes, weight='weight')\n",
    "    \n",
    "    \n",
    "    path = \"./janelia_Comm%d/\"%j\n",
    "    \n",
    "    df_network = pd.read_csv(path+\"network_%.1fum.txt\"%pr, sep=\"\\t\", header=None)\n",
    "    df_network = df_network.rename(columns={0: \"bodyId_pre\", 1: \"bodyId_post\", 2:\"weight\"})\n",
    "    \n",
    "    nodeA_list = df_network.bodyId_pre.tolist()\n",
    "    nodeB_list = df_network.bodyId_post.tolist()\n",
    "    weight_list = df_network.weight.tolist()\n",
    "    \n",
    "    # creating an edge list from adjacency matrix\n",
    "    edge_list=[]\n",
    "    for l,m,w in zip(nodeA_list, nodeB_list, weight_list):\n",
    "        if (l in nodes) and (m in nodes):\n",
    "            edge_list.append( (l,m,{\"weight\":w}))\n",
    "        \n",
    "    G_strah = nx.DiGraph()\n",
    "    \n",
    "    # Add all the nodes to the graph\n",
    "    G_strah.add_nodes_from(nodes)\n",
    "    # Add all the edges to the graph\n",
    "    G_strah.add_edges_from(edge_list)\n",
    "    mod_strah_adjacency = nx.adjacency_matrix(G_strah, nodelist=nodes, weight='weight')\n",
    "    \n",
    "    corr_info = pearsonr(mod_EM_adjacency.toarray().flatten(), mod_strah_adjacency.toarray().flatten())\n",
    "    print(\"Module %d \\t %.3f \\t %.3f\"%(j, corr_info.statistic, corr_info.pvalue))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d0d05-4a82-49b9-b761-9fb097525045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca077a-ba6a-488d-bda0-cd2c453867d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c0dad6e-87a2-4475-b9a3-0ca17df9fdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proximity range: 1 um\n",
      "Overall pearson correlation\n",
      "0.140 \t 0.000\n",
      "\n",
      "\n",
      "Proximity range: 5 um\n",
      "Overall pearson correlation\n",
      "0.135 \t 0.000\n",
      "\n",
      "\n",
      "CPU times: user 26min 39s, sys: 16.6 s, total: 26min 56s\n",
      "Wall time: 27min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# compute pearson correlation between overall ~21000 nodes network corresponding to EM drosophilia\n",
    "# and 8 reconstructed networks(pr range 1um and 5um) grouped together to form large network ~21000 nodes.\n",
    "# in the latter inter-community links do not exist because of the way of construction.\n",
    "for pr in [1,5]:\n",
    "\n",
    "    print(\"Proximity range: %d um\"%pr)\n",
    "    print(\"Overall pearson correlation\")\n",
    "    \n",
    "    nodes=[]\n",
    "    for j in range(8):\n",
    "        \n",
    "        nodes += pd.read_csv(\"./EM_communities/averageSubComm%d_drosophilia.csv\"%j).Node.to_list()\n",
    "        \n",
    "    # EM network\n",
    "    df = pd.read_csv(\"traced-total-connections.csv\")\n",
    "    nodeA_list = df.bodyId_pre.tolist()\n",
    "    nodeB_list = df.bodyId_post.tolist()\n",
    "    weight_list = df.weight.tolist()\n",
    "    \n",
    "    # creating an edge list from adjacency matrix\n",
    "    edge_list=[]\n",
    "    for l,m,w in zip(nodeA_list, nodeB_list, weight_list):\n",
    "        if (l in nodes) and (m in nodes):\n",
    "            edge_list.append( (l,m,{\"weight\":w}))\n",
    "    \n",
    "    G_EM = nx.DiGraph()\n",
    "    \n",
    "    # Add all the nodes to the graph\n",
    "    G_EM.add_nodes_from(nodes)\n",
    "    # Add all the edges to the graph\n",
    "    G_EM.add_edges_from(edge_list)\n",
    "    \n",
    "    mod_EM_adjacency = nx.adjacency_matrix(G_EM, nodelist=nodes, weight='weight')\n",
    "        \n",
    "    # Strahler network\n",
    "    edge_list=[]\n",
    "        \n",
    "    for j in range(8):\n",
    "        path = \"./janelia_Comm%d/\"%j\n",
    "        \n",
    "        df_network = pd.read_csv(path+\"network_%.1fum.txt\"%pr, sep=\"\\t\", header=None)\n",
    "        df_network = df_network.rename(columns={0: \"bodyId_pre\", 1: \"bodyId_post\", 2:\"weight\"})\n",
    "        \n",
    "        nodeA_list = df_network.bodyId_pre.tolist()\n",
    "        nodeB_list = df_network.bodyId_post.tolist()\n",
    "        weight_list = df_network.weight.tolist()\n",
    "        \n",
    "        for l,m,w in zip(nodeA_list, nodeB_list, weight_list):\n",
    "            if (l in nodes) and (m in nodes):\n",
    "                edge_list.append( (l,m,{\"weight\":w}))\n",
    "            \n",
    "    G_strah = nx.DiGraph()\n",
    "    \n",
    "    # Add all the nodes to the graph\n",
    "    G_strah.add_nodes_from(nodes)\n",
    "    # Add all the edges to the graph\n",
    "    G_strah.add_edges_from(edge_list)\n",
    "    mod_strah_adjacency = nx.adjacency_matrix(G_strah, nodelist=nodes, weight='weight')\n",
    "        \n",
    "    corr_info = pearsonr(mod_EM_adjacency.toarray().flatten(), mod_strah_adjacency.toarray().flatten())\n",
    "    print(\"%.3f \\t %.3f\"%(corr_info.statistic, corr_info.pvalue))\n",
    "    print(\"\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb8e87-36ae-466b-b6db-1a8c378573ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
